# GENEL MÄ°MARÄ°

Client
  â†“
FastAPI
  â†“
[1] Regex (Exact Match)
  â†“
[2] Fuzzy Match (Typo tolerant)
  â†“
[3] Semantic Similarity (Sentence Embedding)
  â†“
[4] Local LLM (llama.cpp â€“ reasoning & edge cases)
  â†“
Risk Score + Decision

# ğŸ§  KullanÄ±lan Teknolojiler
API	FastAPI
Exact match	regex
Typo tolerant	rapidfuzz
Semantic	sentence-transformers (TÃ¼rkÃ§e destekli)
LLM	llama.cpp (GGUF model, CPU)
Dil	TÃ¼rkÃ§e

# ğŸ¤– Local LLM SeÃ§imi (CPU Friendly)
Ã–nerilen modeller (GGUF):

BoraBora-Turkish-Llama-3-8B-Instruct.Q4_K_M.gguf
mistral-7b-instruct-v0.2.Q4_K_M.gguf
llama-3-8b-instruct.Q4_K_M.gguf

ğŸ“Œ Q4 quantization â†’ CPU + 8â€“16GB RAM yeterli

#ğŸ“¦ Kurulum
**Libs**
```bash
pip install -r requirements.txt
````
**LLAMA.CPP Apple Silicon / Intel Mac iÃ§in:**
```bash
CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python
```
# ğŸ“ Proje YapÄ±sÄ±
forbidden_ai/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ detector/
â”‚   â”œâ”€â”€ regex_detector.py
â”‚   â”œâ”€â”€ fuzzy_detector.py
â”‚   â”œâ”€â”€ semantic_detector.py
â”‚   â”œâ”€â”€ llm_detector.py
â”‚   â””â”€â”€ risk_engine.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ forbidden_phrases_tr.txt
â”‚
â””â”€â”€ models/
    â””â”€â”€ llama3-turkish.Q4_K_M.gguf


# RUN
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```